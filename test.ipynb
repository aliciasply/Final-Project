{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNaxRmtJ2UPxX7rl49XZnut",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliciasply/Final-Project/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaPbJqEbIVvm",
        "outputId": "fd03f614-78d9-45ba-f4ba-c0e7871df041"
      },
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "try:\n",
        "  spark_version = 'spark-3.1.1'\n",
        "  os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "  # Install Spark and Java\n",
        "  !apt-get update\n",
        "  !apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "  !wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "  !tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "  !pip install -q findspark\n",
        "\n",
        "  # Set Environment Variables\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "  os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "except:\n",
        "  print(f\"Error installing {spark_version}\")\n",
        "finally:\n",
        "  clear_output()\n",
        "  print(f'{spark_version} successfully installed')\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spark-3.1.1 successfully installed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E810kIZBWvWC"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_8Mn4FQWvA9"
      },
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"NaiveBayes\").getOrCreate()"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cl0WOidLVcA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f6b0227-688e-4d76-ffca-830797515e29"
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url =\"https://fakenewsdetector.s3.us-east-2.amazonaws.com/new_test_data.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "test_df = spark.read.csv(SparkFiles.get(\"new_test_data.csv\"), sep=\",\", header=True)\n",
        "test_df.columns\n",
        "# df2 = test_df.select(split(col(\"id\\ttitle\\ttext\\tlabel\"),\"\\t\"))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['id', 'title', 'text', 'label']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEEB0-QyqxvL",
        "outputId": "07e4d6b0-23e2-4cc8-ea30-3d2a0cb0f83c"
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url =\"new_test_data.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "test_df = spark.read.csv(SparkFiles.get(\"new_test_data.csv\"), sep=\",\", header=True)\n",
        "test_df.columns\n",
        "# df2 = test_df.select(split(col(\"id\\ttitle\\ttext\\tlabel\"),\"\\t\"))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['id', 'title', 'text', 'label']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_GTgMlOvICB",
        "outputId": "ba079699-11c2-434c-a6ea-08c480e2dfa5"
      },
      "source": [
        "# Read data\n",
        "from pyspark import SparkFiles\n",
        "url =\"new_test_data2.json\"\n",
        "spark.sparkContext.addFile(url)\n",
        "test_df = spark.read.json(SparkFiles.get(\"new_test_data2.json\"))\n",
        "test_df.columns"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['id', 'label', 'text', 'title']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzf0V_vTLVkb",
        "outputId": "3e28eaa5-ff79-4c7c-c07d-24570790b458"
      },
      "source": [
        "test_df.show()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-----+--------------------+--------------------+\n",
            "|   id|label|                text|               title|\n",
            "+-----+-----+--------------------+--------------------+\n",
            "| 8476| FAKE|Daniel Greenfield...|You Can Smell Hil...|\n",
            "|10294| FAKE|Google Pinterest ...|Watch The Exact M...|\n",
            "| 3608| REAL|U.S. Secretary of...|Kerry to go to Pa...|\n",
            "|10142| FAKE|— Kaydee King (@K...|Bernie supporters...|\n",
            "|  875| REAL|It's primary day ...|The Battle of New...|\n",
            "| 6903| FAKE|  \n",
            "I’m not an imm...|         Tehran, USA|\n",
            "| 7341| FAKE|Share This Baylee...|Girl Horrified At...|\n",
            "|   95| REAL|A Czech stockbrok...|‘Britain’s Schind...|\n",
            "| 4869| REAL|Hillary Clinton a...|Fact check: Trump...|\n",
            "| 2909| REAL|Iranian negotiato...|Iran reportedly m...|\n",
            "| 1357| REAL|CEDAR RAPIDS, Iow...|With all three Cl...|\n",
            "|  988| REAL|Donald Trump’s or...|Donald Trump’s Sh...|\n",
            "| 7041| FAKE|Click Here To Lea...|Strong Solar Stor...|\n",
            "| 7623| FAKE|October 31, 2016 ...|10 Ways America I...|\n",
            "| 1571| REAL|Killing Obama adm...|Trump takes on Cr...|\n",
            "| 4739| REAL|As more women mov...|How women lead di...|\n",
            "| 7737| FAKE|Shocking! Michele...|Shocking! Michele...|\n",
            "| 8716| FAKE|0 \n",
            "Hillary Clinto...|Hillary Clinton i...|\n",
            "| 3304| REAL|Washington (CNN) ...|What's in that Ir...|\n",
            "| 3078| REAL|While paging thro...|The 1 chart that ...|\n",
            "+-----+-----+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0vQSlWrVm2Q"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yyJ9oNGNRL3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdSJYcahNRRV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeTCH386NRXA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZGfMtkXWvMD"
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url =\"https://fakenewsdetector.s3.us-east-2.amazonaws.com/shapiro_cenk.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"shapiro_cenk.csv\"), sep=\",\", header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMFi9HEMWvPz",
        "outputId": "ab6568b3-9c99-4803-e63f-b5bd04b15803"
      },
      "source": [
        "df.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+----------+--------------------+--------------------+----------+-----------+--------------------+-------+---------+--------------------+--------+\n",
            "|            tweet_id|                Time|     Ticks|            TweetUrl|               tweet|UserHandle|   UserName|          RetweetNum|LikeNum|   UserID|             UserUrl|Location|\n",
            "+--------------------+--------------------+----------+--------------------+--------------------+----------+-----------+--------------------+-------+---------+--------------------+--------+\n",
            "| 1374091474220949506|Mon Mar 22 20:11:...|1616443911|https://twitter.c...|\"\"\"They seem to h...|benshapiro|Ben Shapiro|                 176|    868|289548939|https://twitter.c...|    null|\n",
            "| 1374173647150125060|Tue Mar 23 01:38:...|1616463503|https://twitter.c...|https://t.co/KJ25...|benshapiro|Ben Shapiro|                 220|   2266|179245596|https://twitter.c...|    null|\n",
            "| 1374170856893652994|Tue Mar 23 01:27:...|1616462837|https://twitter.c...|RT @elonmusk: Str...|benshapiro|Ben Shapiro|               11928|      0| 17995040|https://twitter.c...|    null|\n",
            "| 1374146219489001473|Mon Mar 22 23:49:...|1616456963|https://twitter.c...|RT @yaf: We are i...|      null|       null|                null|   null|     null|                null|    null|\n",
            "|    As the presid...| Governor @ScottW...|benshapiro|         Ben Shapiro|                 150|         0|   17995040|https://twitter.c...|   null|     null|                null|    null|\n",
            "+--------------------+--------------------+----------+--------------------+--------------------+----------+-----------+--------------------+-------+---------+--------------------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzlY__iGWvTR"
      },
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caCqI500LPGg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5Jl4gLtLPNX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzSiwbUbLPR9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXJBCPdpLPVd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rjdU_PzWvZK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}